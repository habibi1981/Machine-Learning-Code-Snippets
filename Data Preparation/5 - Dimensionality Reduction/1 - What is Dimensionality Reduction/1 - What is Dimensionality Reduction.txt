The number of input variables or features for a dataset is referred to as its dimensionality.
Dimensionality reduction refers to techniques that reduce the number of input variables in a
dataset. More input features often make a predictive modeling task more challenging to model,
more generally referred to as the curse of dimensionality.
High-dimensionality statistics and dimensionality reduction techniques are often used for
data visualization. Nevertheless these techniques can be used in applied machine learning to
simplify a classification or regression dataset in order to better fit a predictive model. In this
tutorial, you will discover a gentle introduction to dimensionality reduction for machine learning
After reading this tutorial, you will know:
. Large numbers of input features can cause poor performance for machine learning algo-rithms.
. Dimensionality reduction is a general field of study concerned with reducing the number of input features.
. Dimensionality reduction methods include feature selection, linear algebra methods, projection methods, and autoencoders.